import { PrismaClient } from '@prisma/client';
import { chunkText, estimateTokens } from './src/services/ai/chunking.js';
import { generateEmbeddingsBatch } from './src/services/ai/embeddings.js';
import { storeChunks } from './src/services/ai/vectorDB.js';

const prisma = new PrismaClient();

/**
 * Seed AI with existing machine data from catalog
 * This converts each machine into a text document and indexes it
 */
async function seedMachinesAI() {
    console.log('ü§ñ Starting AI seeding with machine data...\n');

    try {
        // 1. Get all machines
        const machines = await prisma.machine.findMany({
            include: {
                specifications: true
            }
        });

        console.log(`Found ${machines.length} machines to index\n`);

        // 2. For each machine, create a CatalogItem and Document
        for (const machine of machines) {
            console.log(`\nüì¶ Processing: ${machine.name}`);

            // Create or get CatalogItem
            let catalogItem = await prisma.catalogItem.findUnique({
                where: { code: machine.model }
            });

            if (!catalogItem) {
                catalogItem = await prisma.catalogItem.create({
                    data: {
                        code: machine.model,
                        name: machine.name,
                        category: machine.category,
                        description: `Modelo: ${machine.model} | Categoria: ${machine.category}`
                    }
                });
                console.log(`  ‚úì Created catalog item: ${catalogItem.code}`);
            }

            // Convert machine data to text document
            const machineText = convertMachineToText(machine);
            console.log(`  ‚úì Generated text document (${machineText.length} chars)`);

            // Create Document record
            const document = await prisma.document.create({
                data: {
                    catalogId: catalogItem.id,
                    fileName: `${machine.model}-auto-generated.txt`,
                    fileType: 'text/plain',
                    fileSize: machineText.length,
                    filePath: 'auto-generated',
                    indexed: false,
                    processingProgress: 0
                }
            });

            console.log(`  ‚úì Created document record: ${document.id}`);

            // Process document: chunk and embed
            await processTextToChunks(document.id, machineText, {
                fileName: document.fileName,
                catalogId: catalogItem.id,
                machineName: machine.name,
                machineModel: machine.model,
                category: machine.category
            });

            console.log(`  ‚úÖ Successfully indexed: ${machine.name}`);
        }

        console.log(`\n\n‚úÖ AI seeding complete! Indexed ${machines.length} machines.`);
        console.log('\nüéØ You can now ask questions like:');
        console.log('   - "Quais m√°quinas temos dispon√≠veis?"');
        console.log('   - "Qual a capacidade da m√°quina XYZ?"');
        console.log('   - "Me fale sobre o modelo PAMQIPAU007"');
        console.log('   - "Quais s√£o as especifica√ß√µes da PAGINADORA?"');

    } catch (error) {
        console.error('‚ùå Error seeding AI:', error);
        throw error;
    } finally {
        await prisma.$disconnect();
    }
}

/**
 * Convert machine data to a text document
 */
function convertMachineToText(machine: any): string {
    const parts = [
        `CAT√ÅLOGO DE M√ÅQUINAS - ${machine.category.toUpperCase()}`,
        ``,
        `Nome: ${machine.name}`,
        `Modelo: ${machine.model}`,
        `Categoria: ${machine.category}`,
        ``,
        `ESPECIFICA√á√ïES T√âCNICAS:`,
        ``,
        `Capacidade: ${machine.capacity}`,
        `Pre√ßo: ${machine.price}`,
        ``,
        `Status de Manuten√ß√£o: ${machine.maintenanceStatus}`,
        `√öltima Manuten√ß√£o: ${machine.lastMaintenance}`,
        ``
    ];

    // Add specifications
    if (machine.specifications && machine.specifications.length > 0) {
        parts.push(`ESPECIFICA√á√ïES DETALHADAS:`);
        parts.push(``);
        machine.specifications.forEach((spec: any, index: number) => {
            parts.push(`${index + 1}. ${spec.content}`);
        });
        parts.push(``);
    }

    // Add searchable keywords
    parts.push(`INFORMA√á√ïES ADICIONAIS:`);
    parts.push(`Esta m√°quina est√° catalogada no sistema industrial.`);
    parts.push(`Para consultas sobre manuten√ß√£o, capacidade ou especifica√ß√µes t√©cnicas, consulte as informa√ß√µes acima.`);
    parts.push(`Modelo de refer√™ncia: ${machine.model}`);

    return parts.join('\n');
}

/**
 * Process text into chunks and store with embeddings
 */
async function processTextToChunks(
    documentId: string,
    text: string,
    metadata: any
): Promise<void> {
    try {
        // Update progress
        await prisma.document.update({
            where: { id: documentId },
            data: { processingProgress: 30 }
        });

        // Chunk the text
        const chunks = chunkText(text, {
            chunkSize: 800,
            overlap: 150,
            strategy: 'semantic'
        });

        console.log(`    ‚Üí Created ${chunks.length} chunks`);

        // Update progress
        await prisma.document.update({
            where: { id: documentId },
            data: { processingProgress: 50 }
        });

        // Generate embeddings
        const embeddings = await generateEmbeddingsBatch(chunks);
        console.log(`    ‚Üí Generated ${embeddings.length} embeddings`);

        // Update progress
        await prisma.document.update({
            where: { id: documentId },
            data: { processingProgress: 80 }
        });

        // Store chunks
        await storeChunks(
            documentId,
            chunks.map((content, index) => ({
                content,
                embedding: embeddings[index],
                chunkIndex: index,
                metadata
            }))
        );

        // Update document status
        const totalTokens = chunks.reduce((sum, chunk) => sum + estimateTokens(chunk), 0);
        await prisma.document.update({
            where: { id: documentId },
            data: {
                indexed: true,
                indexedAt: new Date(),
                chunkCount: chunks.length,
                totalTokens,
                processingProgress: 100
            }
        });

        console.log(`    ‚Üí Stored in vector database`);

    } catch (error) {
        await prisma.document.update({
            where: { id: documentId },
            data: {
                indexed: false,
                processingError: (error as Error).message
            }
        });
        throw error;
    }
}

// Run the seed
seedMachinesAI()
    .then(() => process.exit(0))
    .catch((error) => {
        console.error(error);
        process.exit(1);
    });
